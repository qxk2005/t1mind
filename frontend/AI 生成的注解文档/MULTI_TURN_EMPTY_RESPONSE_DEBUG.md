# å¤šè½®å¯¹è¯ç©ºå“åº”è°ƒè¯•

## é—®é¢˜æè¿°

ç”¨æˆ·æŠ¥å‘Šå¤šè½®å¯¹è¯é€»è¾‘å·²è§¦å‘ï¼Œä½† AI è¿”å›äº†ç©ºå“åº”ï¼ŒUI ä¸Šåªæ˜¾ç¤ºå·¥å…·è°ƒç”¨ç»“æœï¼Œæ²¡æœ‰ AI çš„æ€»ç»“å›ç­”ã€‚

## é—®é¢˜åˆ†æ

### âœ… æˆåŠŸçš„éƒ¨åˆ†

ä»æ—¥å¿—å¯ä»¥çœ‹å‡ºï¼Œå¤šè½®å¯¹è¯é€»è¾‘**å·²ç»æˆåŠŸè§¦å‘**ï¼š

```
ğŸ”§ [MULTI-TURN] Stream ended - checking for follow-up. has_agent: true, tool_calls_count: 1
ğŸ”§ [MULTI-TURN] Detected 1 tool call(s), initiating follow-up AI response
ğŸ”§ [MULTI-TURN] Using max_tool_result_length: 4000 chars
ğŸ”§ [MULTI-TURN] Truncating tool result from 4207 to 4000 chars
ğŸ”§ [MULTI-TURN] Calling AI with follow-up context (15524 chars)
ğŸ”§ [MULTI-TURN] Calling AI with question_id: 1759481866
ğŸ”§ [MULTI-TURN] System prompt length: 15524 chars
ğŸ”§ [MULTI-TURN] Follow-up stream started
```

### âŒ é—®é¢˜æ‰€åœ¨

**AI è¿”å›äº†ç©ºå“åº”**ï¼š

```
ğŸ”§ [MULTI-TURN] Follow-up response completed: 0 messages, 0 answer chunks
```

è¿™è¯´æ˜ï¼š
1. âœ… å·¥å…·è°ƒç”¨æˆåŠŸæ‰§è¡Œ
2. âœ… å¤šè½®å¯¹è¯é€»è¾‘æˆåŠŸè§¦å‘
3. âœ… ä¸ AI æœåŠ¡å™¨çš„è¿æ¥æˆåŠŸå»ºç«‹
4. âŒ ä½† AI æ¨¡å‹æ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹

## å¯èƒ½çš„åŸå› 

### 1. System Prompt å¤ªé•¿

```
System prompt length: 15524 chars
```

15524 å­—ç¬¦çš„ system prompt å¯èƒ½æ¥è¿‘æˆ–è¶…è¿‡æŸäº›æ¨¡å‹çš„ä¸Šä¸‹æ–‡é™åˆ¶ï¼š
- GPT-3.5-turbo: ~4K tokens (çº¦ 16K å­—ç¬¦)
- GPT-4: ~8K tokens (çº¦ 32K å­—ç¬¦)
- æŸäº›å°æ¨¡å‹: æ›´å°çš„é™åˆ¶

### 2. åŸå§‹é—®é¢˜æœªæ‰¾åˆ°

`stream_answer_with_system_prompt` æ–¹æ³•ä¼šæ ¹æ® `question_id` ä»æ•°æ®åº“æŸ¥è¯¢åŸå§‹é—®é¢˜ã€‚å¦‚æœï¼š
- question_id å¯¹åº”çš„è®°å½•ä¸å­˜åœ¨
- æˆ–è€…é—®é¢˜å†…å®¹ä¸ºç©º

åˆ™ AI å¯èƒ½æ”¶åˆ°ä¸€ä¸ªç©ºçš„ç”¨æˆ·æ¶ˆæ¯ï¼Œå¯¼è‡´ä¸çŸ¥é“å¦‚ä½•å›å¤ã€‚

### 3. AI æ¨¡å‹é…ç½®é—®é¢˜

ä½¿ç”¨çš„æ¨¡å‹æ˜¯ `google/gemma-3-27b`ï¼Œå¯èƒ½ï¼š
- æ¨¡å‹å¯¹ system prompt çš„æ ¼å¼è¦æ±‚ä¸¥æ ¼
- æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶è¾ƒå°
- æ¨¡å‹æ‹’ç»äº†è¯·æ±‚ä½†æ²¡æœ‰è¿”å›é”™è¯¯

### 4. Follow-up Context æ ¼å¼é—®é¢˜

ç”Ÿæˆçš„ follow_up_context å¯èƒ½æ ¼å¼ä¸å½“ï¼Œå¯¼è‡´ AI æ— æ³•ç†è§£å¦‚ä½•å“åº”ã€‚

## è§£å†³æ–¹æ¡ˆ

### æ·»åŠ è¯¦ç»†è¯Šæ–­æ—¥å¿—

åœ¨ `rust-lib/flowy-ai/src/chat.rs` ä¸­æ·»åŠ äº†ä»¥ä¸‹è¯Šæ–­æ—¥å¿—ï¼š

#### 1. Follow-up Context é¢„è§ˆï¼ˆç¬¬596-602è¡Œï¼‰
```rust
// ğŸ› DEBUG: æ‰“å° follow_up_context çš„é¢„è§ˆï¼ˆåœ¨æ„å»º system_prompt ä¹‹å‰ï¼‰
let context_preview_len = std::cmp::min(500, follow_up_context.len());
let mut safe_preview_len = context_preview_len;
while safe_preview_len > 0 && !follow_up_context.is_char_boundary(safe_preview_len) {
  safe_preview_len -= 1;
}
info!("ğŸ”§ [MULTI-TURN] Follow-up context preview: {}...", &follow_up_context[..safe_preview_len]);
```

**ç›®çš„**: æŸ¥çœ‹å‘é€ç»™ AI çš„ä¸Šä¸‹æ–‡å†…å®¹æ˜¯å¦æ­£ç¡®æ ¼å¼åŒ–

#### 2. æ¯æ¡æ¶ˆæ¯çš„è¯¦ç»†æ—¥å¿—ï¼ˆç¬¬648-650è¡Œï¼‰
```rust
while let Some(message) = follow_up_stream.next().await {
  message_count += 1;
  info!("ğŸ”§ [MULTI-TURN] Received message #{}: {:?}", message_count, 
        if let Ok(ref msg) = message { format!("{:?}", msg) } else { "Error".to_string() });
```

**ç›®çš„**: è¿½è¸ªæ¯æ¡ä» AI æµä¸­æ¥æ”¶åˆ°çš„æ¶ˆæ¯

#### 3. Answer Chunk è¿½è¸ªï¼ˆç¬¬660-663è¡Œï¼‰
```rust
QuestionStreamValue::Answer { value } => {
  answer_chunks += 1;
  has_received_data = true;
  info!("ğŸ”§ [MULTI-TURN] Received answer chunk #{}: {} chars", answer_chunks, value.len());
```

**ç›®çš„**: ç¡®è®¤æ˜¯å¦æ”¶åˆ°äº† AI çš„å›ç­”å†…å®¹

#### 4. ç©ºå“åº”è­¦å‘Šï¼ˆç¬¬694-699è¡Œï¼‰
```rust
if !has_received_data {
  warn!("ğŸ”§ [MULTI-TURN] âš ï¸ No data received from follow-up stream! Possible causes:");
  warn!("ğŸ”§ [MULTI-TURN]   1. AI model returned empty response");
  warn!("ğŸ”§ [MULTI-TURN]   2. System prompt too long ({} chars)", prompt_len);
  warn!("ğŸ”§ [MULTI-TURN]   3. Original question not found for question_id: {}", question_id);
}
```

**ç›®çš„**: æ˜ç¡®æŒ‡å‡ºå¯èƒ½çš„åŸå› ï¼Œä¾¿äºå¿«é€Ÿå®šä½é—®é¢˜

## æµ‹è¯•æ­¥éª¤

### 1. é‡æ–°ç¼–è¯‘è¿è¡Œ

```bash
cd rust-lib/flowy-ai
cargo build
```

### 2. å¤ç°é—®é¢˜

ä½¿ç”¨ç›¸åŒçš„é—®é¢˜æµ‹è¯•ï¼š
- "æ¨è3æœ¬ readwise ä¸­çš„è·Ÿç¦…å®—ç›¸å…³çš„ä¹¦ç±"

### 3. æŸ¥çœ‹æ–°çš„æ—¥å¿—è¾“å‡º

åº”è¯¥ä¼šçœ‹åˆ°ï¼š

```
ğŸ”§ [MULTI-TURN] Stream ended - checking for follow-up. has_agent: true, tool_calls_count: 1
ğŸ”§ [MULTI-TURN] Detected 1 tool call(s), initiating follow-up AI response
ğŸ”§ [MULTI-TURN] Using max_tool_result_length: 4000 chars
ğŸ”§ [MULTI-TURN] Follow-up context preview: ä»¥ä¸‹æ˜¯å·¥å…·è°ƒç”¨çš„ç»“æœï¼Œè¯·åŸºäºè¿™äº›ç»“æœå›ç­”ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼šå·¥å…·è°ƒç”¨: search_readwise_highlights å‚æ•°: {...}...
ğŸ”§ [MULTI-TURN] Calling AI with follow-up context (15524 chars)
ğŸ”§ [MULTI-TURN] Calling AI with question_id: 1759481866
ğŸ”§ [MULTI-TURN] System prompt length: 15524 chars
ğŸ”§ [MULTI-TURN] Follow-up stream started
ğŸ”§ [MULTI-TURN] Received message #1: Answer { value: "æ ¹æ®..." }
ğŸ”§ [MULTI-TURN] Received answer chunk #1: 45 chars
ğŸ”§ [MULTI-TURN] Received message #2: Answer { value: "æ‚¨çš„..." }
ğŸ”§ [MULTI-TURN] Received answer chunk #2: 38 chars
...
ğŸ”§ [MULTI-TURN] Follow-up response completed: 15 messages, 12 answer chunks, has_data: true
```

æˆ–è€…å¦‚æœä»ç„¶å¤±è´¥ï¼š

```
ğŸ”§ [MULTI-TURN] Follow-up stream started
ğŸ”§ [MULTI-TURN] Follow-up response completed: 0 messages, 0 answer chunks, has_data: false
âš ï¸ [MULTI-TURN] âš ï¸ No data received from follow-up stream! Possible causes:
âš ï¸ [MULTI-TURN]   1. AI model returned empty response
âš ï¸ [MULTI-TURN]   2. System prompt too long (15524 chars)
âš ï¸ [MULTI-TURN]   3. Original question not found for question_id: 1759481866
```

### 4. æ ¹æ®æ—¥å¿—è¯Šæ–­

| æ—¥å¿—ç‰¹å¾ | é—®é¢˜è¯Šæ–­ | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| çœ‹åˆ° "Received message #X" ä½†æ—  "Received answer chunk" | AI è¿”å›äº†å…¶ä»–ç±»å‹çš„æ¶ˆæ¯ï¼ˆMetadata/FollowUpï¼‰ | æ£€æŸ¥ AI å“åº”æ ¼å¼ |
| å®Œå…¨æ²¡æœ‰ "Received message" | æµç«‹å³ç»“æŸï¼Œæ²¡æœ‰ä»»ä½•æ•°æ® | æ£€æŸ¥ question_id æ˜¯å¦æœ‰æ•ˆ |
| çœ‹åˆ° "System prompt too long" è­¦å‘Š | ä¸Šä¸‹æ–‡è¶…è¿‡æ¨¡å‹é™åˆ¶ | å‡å° max_tool_result_length |
| Follow-up context å†…å®¹å¼‚å¸¸ | ä¸Šä¸‹æ–‡æ ¼å¼åŒ–é”™è¯¯ | æ£€æŸ¥ tool result å†…å®¹ |

## å¯èƒ½çš„ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: å‡å°å·¥å…·ç»“æœé•¿åº¦

å¦‚æœæ˜¯å› ä¸º system prompt å¤ªé•¿ï¼š

```dart
// åœ¨æ™ºèƒ½ä½“é…ç½®ä¸­
max_tool_result_length: 2000  // ä» 4000 å‡å°åˆ° 2000
```

### æ–¹æ¡ˆ 2: æ£€æŸ¥æ•°æ®åº“ä¸­çš„é—®é¢˜

å¦‚æœæ˜¯å› ä¸º question_id æ— æ•ˆï¼š

```rust
// åœ¨è°ƒç”¨ stream_answer_with_system_prompt å‰æ·»åŠ éªŒè¯
let question = cloud_service.get_question(&workspace_id, &chat_id, question_id).await?;
if question.message.is_empty() {
  error!("ğŸ”§ [MULTI-TURN] Question message is empty for question_id: {}", question_id);
  // ä½¿ç”¨å·¥å…·ç»“æœç›´æ¥æ„å»ºå›ç­”ï¼Œè€Œä¸æ˜¯è°ƒç”¨ AI
}
```

### æ–¹æ¡ˆ 3: ä½¿ç”¨ä¸åŒçš„ AI æ¨¡å‹

å¦‚æœæ˜¯å› ä¸ºæ¨¡å‹é—®é¢˜ï¼š

```
// å°è¯•ä½¿ç”¨ä¸Šä¸‹æ–‡æ›´å¤§çš„æ¨¡å‹
gpt-4-turbo (128K tokens)
claude-3-sonnet (200K tokens)
```

### æ–¹æ¡ˆ 4: æ”¹è¿› Follow-up Prompt æ ¼å¼

å¦‚æœæ˜¯å› ä¸º prompt æ ¼å¼é—®é¢˜ï¼š

```rust
// ç®€åŒ– follow_up_context æ ¼å¼
follow_up_context.push_str("# å·¥å…·æ‰§è¡Œç»“æœ\n\n");
for (req, resp) in &tool_calls_and_results {
  follow_up_context.push_str(&format!(
    "## {}\n\n{}\n\n",
    req.tool_name,
    truncated_result
  ));
}
follow_up_context.push_str("è¯·ç”¨ä¸­æ–‡æ€»ç»“ä»¥ä¸Šä¿¡æ¯å¹¶å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n");
```

## é¢„æœŸç»“æœ

ä¿®å¤ååº”è¯¥çœ‹åˆ°ï¼š

### UI æ˜¾ç¤º
```
[å·¥å…·æ‰§è¡Œç»“æœæ˜¾ç¤º]

---

æ ¹æ®æ‚¨çš„ Readwise ç¬”è®°ï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†3æœ¬ä¸ç¦…å®—ç›¸å…³çš„ä¹¦ç±ï¼š

1. **ã€Šæ´»åœ¨æ­¤æ—¶æ­¤åˆ»ã€‹** - ä¸€è¡Œç¦…å¸ˆ
   è¿™æœ¬ä¹¦ä»‹ç»äº†ç¦…å®—ä¿®ä¹ çš„å…·ä½“æ–¹æ³•ï¼ŒåŒ…æ‹¬çº¦55é¦–åˆè¯­...

2. **ã€Šæ´è§ï¼šä»ç§‘å­¦åˆ°å“²å­¦ã€‹** - ç½—ä¼¯ç‰¹Â·èµ–ç‰¹
   æœ¬ä¹¦ä»å¿ƒç†å­¦è§’åº¦æ¢è®¨äº†ç¦…å®—çš„å†…è§‚ä¿®ä¹ æ–¹æ³•...

3. **ã€ŠThe Way of Zenã€‹** - Alan Watts
   è¿™æœ¬ä¹¦æ·±å…¥è®²è§£äº†å‚ç¦…çš„ä¼ ç»Ÿæ–¹å¼...

è¿™äº›ä¹¦ç±éƒ½å¼ºè°ƒäº†æ­£å¿µã€è§‰çŸ¥å’Œå½“ä¸‹çš„é‡è¦æ€§...
```

### æ—¥å¿—è¾“å‡º
```
ğŸ”§ [TOOL] Tool execution completed: call_001 - success: true
ğŸ”§ [TOOL] Saved tool result for multi-turn. Total saved: 1
ğŸ”§ [MULTI-TURN] Stream ended - checking for follow-up. has_agent: true, tool_calls_count: 1
ğŸ”§ [MULTI-TURN] Detected 1 tool call(s), initiating follow-up AI response
ğŸ”§ [MULTI-TURN] Follow-up context preview: ä»¥ä¸‹æ˜¯å·¥å…·è°ƒç”¨çš„ç»“æœ...
ğŸ”§ [MULTI-TURN] Calling AI with question_id: 1759481866
ğŸ”§ [MULTI-TURN] Follow-up stream started
ğŸ”§ [MULTI-TURN] Received message #1: Answer { value: "æ ¹æ®æ‚¨çš„..." }
ğŸ”§ [MULTI-TURN] Received answer chunk #1: 45 chars
...
ğŸ”§ [MULTI-TURN] Follow-up response completed: 20 messages, 15 answer chunks, has_data: true
```

## ç›¸å…³æ–‡ä»¶

- `rust-lib/flowy-ai/src/chat.rs` - å¤šè½®å¯¹è¯é€»è¾‘å’Œè¯Šæ–­æ—¥å¿—
- `rust-lib/flowy-ai/src/middleware/chat_service_mw.rs` - AI æœåŠ¡è°ƒç”¨
- `MULTI_TURN_CONVERSATION_DEBUG.md` - ä¹‹å‰çš„å¤šè½®å¯¹è¯è°ƒè¯•æ–‡æ¡£
- `TOOL_RESULT_LENGTH_LIMIT_FIX.md` - å·¥å…·ç»“æœé•¿åº¦é™åˆ¶å®ç°

## ä¸‹ä¸€æ­¥

1. **é‡æ–°è¿è¡Œåº”ç”¨**
2. **æµ‹è¯•ç›¸åŒé—®é¢˜**
3. **æä¾›å®Œæ•´çš„æ–°æ—¥å¿—**ï¼Œç‰¹åˆ«æ˜¯ï¼š
   - `ğŸ”§ [MULTI-TURN] Follow-up context preview:` çš„å†…å®¹
   - `ğŸ”§ [MULTI-TURN] Received message #X:` çš„è¾“å‡º
   - æ˜¯å¦æœ‰è­¦å‘Šä¿¡æ¯

è¿™æ ·æˆ‘ä»¬å°±èƒ½å‡†ç¡®åˆ¤æ–­é—®é¢˜åŸå› å¹¶æä¾›é’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆï¼

