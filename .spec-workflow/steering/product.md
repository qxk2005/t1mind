# 产品舵手文档：AppFlowy AI 全局模型与 OpenAI 兼容服务器支持

## 背景与愿景
AppFlowy 已内置本地 LAI（基于 Ollama）的 AI 能力，但用户也常使用 OpenAI 兼容的第三方/自建服务器（如 OpenAI API、DeepSeek、Moonshot、Azure OpenAI、OpenRouter 等）。本迭代的愿景是：
- 允许在“AI 设置”中选择全局使用的模型来源（本地 Ollama 或 OpenAI 兼容服务器），并默认开启 LAI。
- 在不牺牲隐私与离线优势的前提下，提供对 OpenAI 兼容服务器的灵活配置与可用性测试。
- 所有使用 AI 能力的场景（聊天、补全、RAG、写作助手等）统一按全局选择的模型类型走对应配置。
- 保持跨平台一致体验与可靠性（macOS、Windows、Android），并支持中英文界面。

## 目标（Goals）
- 在“全局设置 → AI 设置”中新增“全局使用的模型类型”选择：
  - 选项：
    - “ollama 本地”（保持现有 LAI/Ollama 设置，默认开启）
    - “openai 兼容服务器”（进入独立配置页签）
- 新增“OpenAI 兼容服务器”配置页签，支持填写并持久化保存：
  - 聊天 API 端点（base url 或完整 chat 路径）
  - 聊天 API 密钥
  - 聊天模型名称
  - 模型类型（推理模型/普通模型）
  - 最大 tokens
  - 温度（temperature）
  - 超时时间
  - 一键“测试聊天模型”可用性
- 嵌入模型独立配置与测试：
  - 嵌入 API 端点
  - 嵌入 API 密钥
  - 嵌入模型名称
  - 一键“测试嵌入模型”可用性
- 设置的持久化保存、读取与跨平台一致行为。
- 切换全局模型类型后，AI 聊天/补全/问答默认走对应配置（无须二次选择）。
- 保持中英文 i18n（简体中文、英文）。

## 非目标（Non-Goals）
- 本期不实现多提供方自动回退或智能路由。
- 本期不提供按页面/工作区的多粒度覆盖策略（仅全局生效）。
- 本期不涉及云计费、用量展示或速率限制策略。
- 本期不实现 iOS 端适配（目标平台：macOS、Windows、Android）。

## 用户价值与场景
- 本地优先用户：继续默认使用 LAI（Ollama），离线、隐私友好。
- 团队/开发者：可切换到 OpenAI 兼容服务器，统一对接组织已有的 LLM 后端或推理型模型。
- 研究/写作爱好者：根据任务切换“推理模型/普通模型”，提升长推理任务与写作任务的效果。

## 关键体验（UX）概要
- “AI 设置”顶部：
  - “AppFlowy Local AI（LAI）”默认开启状态文案与状态指示维持现状。
  - 新增下拉框“全局使用的模型类型”：
    - 选择“ollama 本地”→ 展示/保留当前的 `LocalAISetting` 面板。
    - 选择“openai 兼容服务器”→ 展示一个新的“OpenAI 兼容服务器”页签（Tab）或面板。
- “OpenAI 兼容服务器”页签包含两个区块：
  - 聊天模型配置与测试：输入端点、密钥、模型名、模型类型、最大 tokens、温度、超时，并提供“测试聊天模型”按钮，测试通过给予明显反馈。
  - 嵌入模型配置与测试：输入端点、密钥、模型名，提供“测试嵌入模型”按钮。
- 交互期望：
  - 字段变更后可“保存”，保存成功/失败有 Toast 或提示信息。
  - “测试”不写入持久化，仅校验可用性并展示结果。

## 成功标准（Acceptance Criteria）
- 选择“全局使用的模型类型”后，应用所有 AI 功能默认使用对应后端：
  - 选择 Ollama：沿用现有 LAI 行为。
  - 选择 OpenAI 兼容服务器：聊天/补全/嵌入均走配置的兼容端点。
- “测试聊天模型”“测试嵌入模型”在 macOS、Windows、Android 上正常工作，并能清晰提示成功/失败与错误原因（如超时、401、404、模型不存在等）。
- 配置信息写入持久化存储，重启应用后仍然生效。
- 所有新增 UI 与文案具有中英文翻译。
- 不影响现有 Ollama/LAI 的使用与稳定性。

## 里程碑与可视化产出
为确保“步步为营”，每个里程碑都能在 UI 上直接看到变化或通过测试按钮直观验证。

1) 里程碑 A：基础 UI 与 i18n
- 可视化产出：
  - “AI 设置”增加“全局使用的模型类型”下拉；
  - 新增“OpenAI 兼容服务器”页签骨架（字段占位、保存/测试按钮）；
  - 中英文文案可切换；
- 验收：界面元素可见、交互无报错。

2) 里程碑 B：配置持久化与读取
- 可视化产出：
  - 填写字段后“保存”提示成功，重新进入设置仍能看到保存值；
- 验收：重启应用配置不丢失；错误保存有明确提示。

3) 里程碑 C：测试能力（聊天/嵌入）
- 可视化产出：
  - 点击“测试聊天模型”“测试嵌入模型”能得到成功/失败提示；
- 验收：对常见错误返回明确原因（密钥无效、超时、模型名错误、端点不可达）。

4) 里程碑 D：全局生效与回归
- 可视化产出：
  - 在 AI 聊天/补全等功能中，无需再选择提供方，自动走全局选择；
- 验收：
  - 切到“openai 兼容服务器”后，日志/提示可表明请求走兼容端点；
  - 切回“ollama 本地”后，恢复走本地 LAI；
  - 不影响既有功能与性能。

## 约束与兼容性
- 平台：macOS、Windows、Android。
- 国际化：简体中文、英文。
- 隐私：不默认上传任何内容到远程；仅在用户选择“openai 兼容服务器”并触发相关功能时，才发起对该端点的网络请求。

## 关键风险与缓解
- 不同“OpenAI 兼容”实现的细节差异（路径、字段、流式 vs 非流式）。
  - 缓解：将端点、模型、温度、超时等作为可配置项；测试按钮覆盖常见错误。
- 推理模型与普通模型在参数/格式上的差异。
  - 缓解：在“模型类型”进行明确选择，并按类型设置合理的默认参数与提示。
- 跨平台网络/证书问题（Android 网络权限、桌面证书链）。
  - 缓解：在测试按钮中输出可诊断的错误信息；文档提示常见排错方式。

## 路线图之外的扩展可能
- 后续可增加每工作区/每页面的覆盖策略；
- 增加多提供方优先级与回退；
- 内置更多常见 OpenAI 兼容厂商预设模板，降低填写成本。

## 参考（现有相关模块，仅作定位）
- Flutter 设置页面：`frontend/appflowy_flutter/lib/workspace/presentation/settings/pages/setting_ai_view/settings_ai_view.dart`
- 本地 LAI/Ollama 设置：`frontend/appflowy_flutter/lib/workspace/presentation/settings/pages/setting_ai_view/local_ai_setting.dart`
- 模型类型选择：`frontend/appflowy_flutter/lib/workspace/presentation/settings/pages/setting_ai_view/model_selection.dart`
- Rust LAI 控制器与嵌入：`frontend/rust-lib/flowy-ai/src/local_ai/`、`frontend/rust-lib/flowy-ai/src/embeddings/`

—— 本文档用于指导后续技术与结构文档以及 SPEC 任务分解，确保每步均可观测与验证。


