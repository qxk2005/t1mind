# Requirements — AppFlowy: AI 全局模型与 OpenAI 兼容服务器支持

## 1. 概述
为 AppFlowy 增加除本地 Ollama（LAI）外的“OpenAI 兼容服务器”作为可选全局推理提供方。在“设置 → AI 设置”中：新增“全局使用的模型类型”下拉（二选一：Ollama 本地、OpenAI 兼容服务器），并在选择后进入相应的详情配置页签。默认开启 LAI。本次改造需覆盖聊天与嵌入两条能力线，支持配置、测试与持久化，且在应用中统一按全局选择生效。

支持平台：macOS、Windows、Android。支持语言：简体中文、英文。

## 2. 目标与非目标
- 目标：
  - 新增“全局使用的模型类型”选择：Ollama 本地 / OpenAI 兼容服务器。
  - OpenAI 兼容服务器配置项（聊天）：聊天 API 端点、API 密钥、模型名称、模型类型（推理/普通）、最大 tokens、温度、超时时间，含“测试聊天模型”。
  - OpenAI 兼容服务器配置项（嵌入）：嵌入 API 端点、嵌入 API 密钥、嵌入模型名称，含“测试嵌入模型”。
  - 配置可持久化；应用重启后仍有效。
  - 一旦选择全局模型类型，AI 聊天/补全/问答等默认使用对应配置（无需再次选择）。
  - 默认开启 AppFlowy Local AI（LAI），不影响既有功能稳定性。
  - 完整 i18n（中/英）。
- 非目标：
  - 不实现多提供方自动回退或智能路由。
  - 不提供按页面/工作区的粒度覆盖（仅全局）。
  - 不涉及云计费、额度用量与速率策略。
  - iOS 暂不覆盖。

## 3. 用户故事（EARS）
- 当用户打开“AI 设置”时，系统应展示“全局使用的模型类型”下拉，默认为“ollama 本地”。
- 当用户选择“openai 兼容服务器”时，系统应展示“OpenAI 兼容服务器”页签，包含聊天与嵌入的配置与测试入口。
- 当用户在聊天配置中填写端点、密钥、模型名、模型类型、最大 tokens、温度与超时时间并点击“保存”时，系统应校验并持久化保存；失败时给出明确错误信息。
- 当用户点击“测试聊天模型”时，系统应调用配置的兼容端点并返回测试结果（成功或明确的错误原因）。
- 当用户在嵌入配置中填写端点、密钥、模型名并点击“保存/测试”时，系统应执行相同的校验与反馈逻辑。
- 当用户完成全局模型类型设置后，在 AI 聊天/补全等功能中，系统应默认使用对应后端，无需二次选择。
- 当系统无法连接到配置端点或鉴权失败时，系统应给出本地化的可读错误提示（示例：超时、401、404、模型不存在、响应格式错误）。

## 4. 功能性需求
### 4.1 全局模型类型选择
- 下拉项：
  - ollama 本地（默认）
  - openai 兼容服务器
- 切换后展示对应详情页签（保留原有 LocalAISetting；新增 OpenAI 兼容设置页签）。

### 4.2 OpenAI 兼容服务器 — 聊天配置
- 字段：
  - 聊天 API 端点（必填，Base URL 或标准 Chat Completions 路径）
  - 聊天 API 密钥（必填，受保护存储）
  - 聊天模型名称（必填）
  - 模型类型：推理模型 / 普通模型（必选）
  - 最大 tokens（可选，数字，边界校验）
  - 温度（可选，0.0–2.0，边界校验）
  - 超时时间（可选，毫秒，边界校验）
- 行为：
  - 保存：字段校验、持久化；成功/失败提示。
  - 测试：不持久化，仅发起一次请求并返回结果（成功/具体错误）。
  - 流式与非流式：在不破坏现有流式体验前提下，优先支持流式响应。

### 4.3 OpenAI 兼容服务器 — 嵌入配置
- 字段：嵌入 API 端点、嵌入 API 密钥、嵌入模型名称（同上校验）。
- 行为：保存与测试逻辑同聊天配置。

### 4.4 持久化与默认生效
- 所有配置与全局模型类型需本地持久化（跨平台一致）。
- 应用内任意使用 AI 能力的模块默认读取全局配置并直连对应后端。

### 4.5 国际化与可访问性
- 文案提供 zh-CN 与 en-US。
- 错误提示可读、具体、避免术语堆砌；交互控件具备可访问性标签。

## 5. 非功能性需求
- 安全：API Key 仅本地存储，传输仅用于直连；日志脱敏。
- 性能：常规请求 P95 响应 < 5s；流式首包 < 2s（在网络可用前提下）。
- 可靠性：错误类型明确（网络、鉴权、模型不可用、格式不兼容、超时）。
- 兼容性：适配主流 OpenAI 兼容行为（路径、headers、SSE/chunk）。

## 6. 验收标准（按里程碑）
- 里程碑 A：UI 与 i18n
  - 能显示全局模型类型下拉与 OpenAI 兼容页签骨架；中文/英文可切换。
- 里程碑 B：持久化
  - 字段保存成功并可在重启后读取；错误保存有提示。
- 里程碑 C：测试能力
  - “测试聊天模型”“测试嵌入模型”在三平台返回成功/错误；错误含具体原因。
- 里程碑 D：全局生效
  - 切至 openai 兼容后，聊天/补全默认走远端；切回 ollama 后恢复本地。

## 7. 约束与依赖
- 平台：macOS、Windows、Android。
- 依赖模块：
  - Flutter 设置页面与 BLoC：`settings_ai_view.dart`、`local_ai_setting.dart`、（新增）`openai_compatible_setting.dart`、对应 BLoC。
  - Rust 后端：`flowy-ai` 新增 openai_compatible 模块（client/chat/embeddings/controller），与 KV 持久化键。
  - Proto：新增 OpenAI 兼容设置与测试相关消息与事件。

## 8. 风险与应对
- 不同兼容实现差异：通过可配置项与测试按钮覆盖；错误提示清晰。
- 流式实现差异：支持 SSE 与 chunk，两者择一或适配。
- 证书/网络问题：提示常见排错与超时设置；Android 网络权限校验。

## 9. 退出准则
- 全部验收标准满足；不影响现有 LAI/Ollama 功能；三平台验证通过；文案可切换；配置持久化可靠。
